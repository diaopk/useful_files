/* lower limit - 200,010 posts */
select count(*) from posts where posts.ViewCoddunt > 28465;

/* 1st interval 49,997 posts */
select count(*) from posts where posts.viewCount > 28464 and posts.ViewCount < 36444;

/* 2nd interval 50,001 posts */
select count(*) from posts where posts.viewCount > 36444 and posts.ViewCount < 50821;

/* 3rd  interval 50,000 posts */
select count(*) from posts where posts.ViewCount > 50821 and posts.ViewCount < 86334;

/* 4th  interval 49,997 posts */
select count(*) from posts where posts.ViewCount > 86334;

/* =============== Pig ============== */
-- load 1st posts 
posts1 = load './posts_1.csv' using PigStorage(',') as (id:int, PostTypeId:int, AcceptedAnswerId:int, ParentId:int, CreationDate:datetime, DeletionDate:datetime, Score:int, ViewCount:int, OwnerUserId:int, OwnerDisplayName:chararray, LastEditorUserId:int, LastEditorDisplayName:chararray, LastEditDate:datetime, LastActivityDate:datetime, Title:chararray, Tags:chararray, AnswerCount:int, CommentCount:int, FavoriteCount:int, ClosedDate:datetime, CommunityOwnedDate:datetime);

-- Do the similar operaions for posts2, posts3 and posts4 
-- Union them 
posts = UNION posts1, posts2, posts3, posts4;

-- Store the union data 
STORE posts INTO '<pig_output-path>' USING PigStorage(',');

/* =============== Hive ================= */
-- create a database
CREATE DATABASE assignment1;

-- create a posts table
CREATE TABLE IF NOT EXISTS posts
(id INT, PostTypeId INT, AcceptedAnswerId INT, ParentId INT, CreationDate TIMESTAMP, DeletionDate TIMESTAMP, Score INT, ViewCount INT, Body STRING, OwnerUserId INT, OwnerDisplayName STRING, LastEditorUserId INT, LastEditorDisplayName STRING, LastEditDate TIMESTAMP, LastActivityDate TIMESTAMP, Title STRING, Tags STRING, AnswerCount INT, CommentCount INT, FavoriteCount INT, ClosedDate TIMESTAMP, CommunityOwnedDate TIMESTAMP)
COMMENT 'Posts of Stackover Exchange' ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' STORED AS TEXTFILE [LOCATION <input-path>];

-- load the data generated by Pig 
-> LOAD DATA INPATH <path-to-file> INTO TABLE posts;

/* TASK 1 - the top 10 posts by score */
SELECT id,score FROM posts ORDER BY score DESC LIMIT 10;
/*
# Result
OK
22586
19063
14715
10726
9517
8943
8112
7894
7733
7676
Time taken: 2.906 seconds, Fetched: 10 row(s)
*/

/* TASK 2 - the top 10 users by post score */
SELECT OwnerUserId AS user_id, SUM(score) AS scores FROM posts GROUP BY OwnerUserId ORDER BY scores DESC LIMIT 10;
-- But I found that there is NULL OwnerUserId
/*
OK
user_id   scores
NULL	    318749
87234	    32477
4883	    22784
9951	    22628
6068	    21507
89904	    19731
51816	    16542
49153	    15644
95592	    15409
63051	    14858
Time taken: 3.879 seconds, Fetched: 10 row(s)
*/

-- Now I check how many OwnerUserId is NULL by the following query
SELECT COUNT(*) FROM posts WHERE OwnerUserId IS NULL;
/*
result
4982
Time taken: 1.646 seconds, Fetched: 1 row(s)
*/

-- So I need to filter out all NULL OwnerUserId 
SELECT OwnerUserId AS user_id, SUM(score) AS scores FROM posts 
WHERE OwnerUserId IS NOT NULL GROUP BY OwnerUserId ORDER BY scores DESC 
LIMIT 10;
/*
user_id   scores
87234	    32477
4883	    22784
9951	    22628
6068	    21507
89904	    19731
51816	    16542
49153	    15644
95592	    15409
63051	    14858
39677	    14794
Time taken: 3.77 seconds, Fetched: 10 row(s)
*/

-- To see how many scores users get and how many posts they made 
SELECT OwnerUserId AS user_id, SUM(score) AS scores, COUNT(*) AS post_count
FROM posts WHERE OwnerUserId IS NOT NULL GROUP BY OwnerUserId ORDER BY scores DESC 
LIMIT 10;

/* TASK 3 - The number of distinct users who used th word 'hadoop' in one of their
posts. */
-- First I use Pig to filter out all posts which has 'hadoop' in it.
-- then import to the hive 
filter_posts = FILTER posts BY (Body MATCHES '.*hadoop.*');
-- Store filter_posts 
STORE filter_posts INTO '<pig_output>' USING PigStorage(',');
-- In Hive, check how many of them
SELECT COUNT(*) FROM filter_posts;
/*
89
Time taken: 4.689 seconds, Fetched: 1 row(s)
*/

-- check users and their number of poosts wiht 'hadoop' in them
SELECT OwnerUserId, COUNT(*) AS post_count FROM filter_posts GROUP BY OwnerUserId;
-- we can see that there are NULL OwnerUserId. So we better remove NULL by the 
-- following query
SELECT OwnerUserId, COUNT(*) AS post_count 
FROM filter_posts WHERE OwnerUserId IS NOT NULL GROUP BY OwnerUserId;
-- Now get the final answer 
SELECT COUNT(DISTINCT OwnerUserId) FROM filter_posts WHERE OwnerUserId IS NOT NULL;
/*
OK
88
Time taken: 1.798 seconds, Fetched: 1 row(s)
*/

/* ============ TASK 4 ================ */
-- Filter the top 10 users by score in Pig
groupby_user_p = group p by OwnerUserId;
user_score_sum = foreach groupby_user_p generate p.OwnerUserId, SUM(p.Score) AS (Score: INT);
ordered_uesr_score = order user_score_sum by Score DESC;
limit_user_score = limit ordered_user_score 15;
foreach_limit_user_score = FOREACH limit_user_score GENREATE FLATTEN($0), Score;
final = DISTINCT foreach_limit_user_score;
-- However I am not able to generate user_id and associated body content ordered by
-- score. Instead, I use hive to do so
-- Hive output file for python mr in csv format
INSERT OVERWRITE LOCAL DIRECTORY <paht-to-output> 
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
SELECT owneruserid, body FROM full_posts WHERE owneruserid IN 
(SELECT top10user.user_id FROM 
  (SELECT owneruserid AS user_id, SUM(score) AS score FROM posts 
    WHERE owneruserid IS NOT NULL GROUP BY  owneruserid ORDER BY score DESC limit 10)   AS top10user);
